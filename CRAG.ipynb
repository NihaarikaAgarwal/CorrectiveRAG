{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CpG7w2B4_hEy",
    "outputId": "7859392c-f328-4485-efa1-a1103cb85200"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.2.0\n",
    "#!pip install langchain-openai==0.1.7\n",
    "!pip install langchain-community==0.2.0\n",
    "!pip install langgraph==0.1.1\n",
    "!pip install langchain-chroma==0.1.1\n",
    "!pip install huggingface_hub\n",
    "!pip install --force-reinstall chromadb==0.5.23 tokenizers==0.20.3 transformers==4.29.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYqQ1UagCs-u",
    "outputId": "41cf132c-687b-4e10-f635-84e9b88ff432"
   },
   "outputs": [],
   "source": [
    " !pip install -q --force-reinstall chromadb==0.4.24 transformers==4.28.1 tokenizers==0.13.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtebIdtgDWJd",
    "outputId": "50b2c3c5-ecb6-4173-87c6-5c7acbb3daa8"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from huggingface_hub import InferenceClient\n",
    "huggingface_key = getpass('Enter your hugging face API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0A06faFkW37",
    "outputId": "90b1d800-1900-4120-8fb8-6c5b9882b832"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter your Tavily API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3axaNrIFq1x",
    "outputId": "3af4f413-2d69-4b06-be10-131add9404e6"
   },
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "# openai_key = getpass('Enter your OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zos8LKx4kSfZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_key\n",
    "#os.environ['OPENAI_API_KEY'] = openai_key\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2j-S3DFlB3N"
   },
   "source": [
    "Build search index for wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH68psh_kScz"
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# openai_embedding = OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Tmb769IQHWqa",
    "outputId": "000f7c73-302c-4cf6-8a19-17d616804d86"
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxdWEmottTXL",
    "outputId": "315d2d6d-6bef-450e-f385-07e07a7fbdf9"
   },
   "outputs": [],
   "source": [
    "!pip install scipy==1.10.1 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UR6GvUEStfF6",
    "outputId": "ab5a904b-0857-482b-e492-6aad88f67c7c"
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5v8iGbhzHOj7",
    "outputId": "0f33bbff-87d3-45ce-ef94-b172f97324bf"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIS-DCaJEy8L",
    "outputId": "72a4190c-0585-4b54-8cc0-a6d1bfc31def"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "wikipedia_filepath = '/content/sample_data/simplewiki-2020-11-01.jsonl'\n",
    "docs = []\n",
    "\n",
    "with open(wikipedia_filepath, 'r', encoding='utf-8') as fIn:\n",
    "    for line in fIn:\n",
    "        data = json.loads(line.strip())\n",
    "        # only first 3 paras\n",
    "        text = ''.join(data.get('paragraphs', [])[:3])\n",
    "        metadata = {\n",
    "            \"title\": data.get('title'),\n",
    "            \"article_id\": data.get('id')\n",
    "        }\n",
    "        docs.append({'metadata': metadata, 'data': text})\n",
    "\n",
    "# taking subset to keep small in size\n",
    "docs = [doc for doc in docs if 'india' in doc['data'].lower()]\n",
    "\n",
    "# create docs\n",
    "langchain_docs = [\n",
    "    Document(page_content=doc['data'], metadata=doc['metadata']) for doc in docs\n",
    "]\n",
    "\n",
    "# chunk docs\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "chunked_docs = splitter.split_documents(langchain_docs)\n",
    "\n",
    "for i, chunk in enumerate(chunked_docs[:3]):\n",
    "    print(f\"Chunk {i+1}:\\n\", chunk.page_content[:500], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qo-kQG0fkSX3",
    "outputId": "96864a15-1d9b-4acd-f110-e745df63af61"
   },
   "outputs": [],
   "source": [
    "len(chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxwgM_GokSVR",
    "outputId": "f0019f64-546d-490a-f96d-2dba359facc3"
   },
   "outputs": [],
   "source": [
    "chunked_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJHsx7JAIUUP",
    "outputId": "ba0f53f4-9a0e-45d1-e2ca-afc9d061f499"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39jY6hS-eNRH",
    "outputId": "c15b3861-2443-4a07-e477-67234a571301"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"content_db\", ignore_errors=True)\n",
    "print(\"Removed existing content_db before rebuild\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fjn30NeJH7E5",
    "outputId": "991dc730-fe99-49b4-c363-cfc3a4ca1ab7"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from tqdm import tqdm\n",
    "#vector db\n",
    "#test_docs = chunked_docs[:1]\n",
    "# remove duplicates\n",
    "unique_docs = list({doc.page_content: doc for doc in chunked_docs}.values())\n",
    "documents = list(tqdm(unique_docs, desc=\"Embedding Chunks\"))\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=unique_docs,\n",
    "    collection_name='wikipedia_data_indexed',\n",
    "    embedding=embedding_model,\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "    persist_directory=\"content_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muPwQW4CMysa",
    "outputId": "cecfae76-0808-452e-e695-6d593d88f6ea"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Directory exists:\", os.path.exists(\"content_db\"))\n",
    "print(\"Contents:\", os.listdir(\"content_db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX_2CKTKNDOX",
    "outputId": "ab97dc9c-98cb-4c69-cdc1-2b5732f68e6a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "abs_path = os.path.abspath(\"content_db\")\n",
    "print(\"Chroma DB stored at:\", abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aU4qXDpAR1hS",
    "outputId": "08067512-c3a1-4cc6-c615-d34f8ec59b45"
   },
   "outputs": [],
   "source": [
    "print(\" Total docs in vectorstore:\", len(vectorstore.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrkGOyOAqeCI"
   },
   "source": [
    "Retreival with similarity threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKKsHtGJkSIC"
   },
   "outputs": [],
   "source": [
    "# vectorstore = Chroma(\n",
    "#     collection_name='wikipedia_data_indexed',\n",
    "#     embedding_function=embedding_model,\n",
    "#     persist_directory=\"wikipedia_db\"\n",
    "# )\n",
    "similarity_threshold = vectorstore.as_retriever(search_type='similarity_score_threshold', search_kwargs={\"k\" : 5,\"score_threshold\":0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atIy3BTWpUUS",
    "outputId": "59484e5d-410b-46c7-8bb3-dc2a8d290ab4"
   },
   "outputs": [],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "top5_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdWLB5aoEwQS",
    "outputId": "54764ea6-346f-4e13-b102-f7fd276f9af8"
   },
   "outputs": [],
   "source": [
    "for i, doc in enumerate(top5_docs):\n",
    "    print(f\"Doc {i+1}:\\n{doc.page_content[:200]}\")\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXn6bbUbgXr0",
    "outputId": "6485f8db-c70d-4a75-c25e-3e1a1f948557"
   },
   "outputs": [],
   "source": [
    "query = \"what is Langraph\"\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "top5_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cpi_RdWrQZu"
   },
   "source": [
    "create query retrieval grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2Cnlf2Pz6Pe",
    "outputId": "1060772a-dcea-4c2c-fe70-42a55e2d574a"
   },
   "outputs": [],
   "source": [
    "!pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2567ede698a5491eaaaa764e117cc25d",
      "c0f33e32201846039c8d75feb2bd7963",
      "bc9ade5ec6254f75ab7d8768c2b6f76f",
      "91463a3f0ebe4ccfb1cc6dd8b905dbf8",
      "d01f489d0f004ed9b5a0483295dc3e5f",
      "6d3a019b2b4b4448a1363fd1eb4a062d",
      "22644239a38649978d9517b4a3fddced",
      "ed651bb4c85e451db4342e4ac9a824ca",
      "06ec8e1499534c0183b430fe90193c9f",
      "54c1373449be446b8e7e254b0390d283",
      "e95a7ff52a2342af95b152ec82ca367b",
      "64870ac096f9464b95980a054f3b2268",
      "b56bffff5c4a4cd6840e132c71e84a1c",
      "861d224712e844cbb67bbc3ff49f4ac7",
      "6cd7cb4325c148c49def5e0bad5cbb64",
      "165eb522635d471780de9d08a6193c92",
      "5b05f070c64a43fdbf63854fea615d49",
      "ee8feacf53b54a3ab4a3d84a6eb82a7d",
      "5d9a23a8d54b474782a6c679b22dac4d",
      "68c916f7cc284d4898879b414c7772fa",
      "2d76f3b7c1ae45d1a34cdc4f4c569caa",
      "9641f6071d0f4cd9b8b162d4d6ca6a8a"
     ]
    },
    "id": "ytJBGtZjzPiw",
    "outputId": "1d7b94f4-843b-4b57-85a2-fba311f27164"
   },
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    max_new_tokens=128,\n",
    "    context_length=4096,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtwMl0ZtzwqP"
   },
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "from langchain_core.language_models import LLM\n",
    "\n",
    "class CTransformersLLM(LLM):\n",
    "    model: Any\n",
    "\n",
    "    def _call(self, prompt: str, stop: List[str] = None) -> str:\n",
    "        output = self.model(prompt)\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                output = output.split(s)[0]\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self):\n",
    "        return {\"model\": \"ctransformers\"}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ctransformers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDi7Bwk2z5fN"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "#llm = CTransformersLLM(model=llm)\n",
    "\n",
    "SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n",
    "Respond in **valid JSON** ONLY and on a single line.\n",
    "Your answer must be exactly one of these:\n",
    "{{ \"binary_score\": \"yes\" }}\n",
    "or\n",
    "{{ \"binary_score\": \"no\" }}\n",
    "Do not write anything else. No 'Grader:', no explanation.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Retrieved document: {document}\\nUser question: {question}\")\n",
    "])\n",
    "\n",
    "\n",
    "llm = CTransformersLLM(model=llm)\n",
    "parser = PydanticOutputParser(pydantic_object=GradeDocuments)\n",
    "\n",
    "doc_grader: Runnable = grade_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky_4rvJZ2Om2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json(text):\n",
    "    match = re.search(r\"\\{.*?\\}\", text)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIDYltfB6sw8"
   },
   "outputs": [],
   "source": [
    "def safe_invoke_with_json_extraction(chain, inputs):\n",
    "    from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke(inputs)\n",
    "        return result.dict() if hasattr(result, \"dict\") else result\n",
    "    except OutputParserException as e:\n",
    "        raw = e.llm_output.strip()\n",
    "        print(\"Parsing failed. Raw output:\\n\", raw)\n",
    "        data = extract_json(raw)\n",
    "        if data:\n",
    "            return data\n",
    "        else:\n",
    "            return {\"binary_score\": \"unclear\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EdjuIvp6vXB",
    "outputId": "56c8b747-27a5-418f-ff63-07653810d8a3"
   },
   "outputs": [],
   "source": [
    "response = safe_invoke_with_json_extraction(doc_grader, {\n",
    "    \"document\": \"India is a country in South Asia with a long cultural history.\",\n",
    "    \"question\": \"Where is India located?\"\n",
    "})\n",
    "\n",
    "print(\" Binary Score:\", response[\"binary_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwyWCHKK7kgk",
    "outputId": "90ae9359-7253-4521-8767-f045c0c73dbb"
   },
   "outputs": [],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "\n",
    "for doc in top5_docs:\n",
    "    print(\"Document:\\n\", doc.page_content)\n",
    "\n",
    "    result = safe_invoke_with_json_extraction(doc_grader, {\n",
    "        \"question\": query,\n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "\n",
    "    print(\"GRADE:\", result[\"binary_score\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-0RHjG9JQwH",
    "outputId": "3f183782-89ec-4e7e-fb0f-ba7e66f0d25c"
   },
   "outputs": [],
   "source": [
    "query = \"what is Langraph?\"\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "\n",
    "for doc in top5_docs:\n",
    "    print(\"Document:\\n\", doc.page_content)\n",
    "\n",
    "    result = safe_invoke_with_json_extraction(doc_grader, {\n",
    "        \"question\": query,\n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "\n",
    "    print(\"GRADE:\", result[\"binary_score\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9wPQbCAzEk1",
    "outputId": "f75aa82c-afd9-42a5-9a4e-c303722f4af0"
   },
   "outputs": [],
   "source": [
    "query = \"who won the champions league in 2024?\"\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "\n",
    "for doc in top5_docs:\n",
    "    print(\"Document:\\n\", doc.page_content)\n",
    "\n",
    "    result = safe_invoke_with_json_extraction(doc_grader, {\n",
    "        \"question\": query,\n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "\n",
    "    print(\"GRADE:\", result[\"binary_score\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZewHK2V1hhuY"
   },
   "source": [
    "build qa rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "fe62d743a4024d358d64efdcac8ce2ab",
      "37819507532a4ce695e6165d449bd53b",
      "a51360fba6c34d92a579544292ede000",
      "8adcc5fcd9864587b35b87d6dbff7332",
      "6e151ff2701a464db3dcad5e0cafe1ec",
      "5c095561fe384a3f82ff04571ccfcbce",
      "bb6cfc028f0a48a9ae366ab754598e4b",
      "58dc5e29f0174a3ca721797ec57b1c51",
      "3f32d54fc0c74c35af7aef28b8096638",
      "824d97b7d00041e59e8a8b8599453a20",
      "45b713e6b9f949fea9054f1672453674",
      "0781df0ebcd34e9b9cf833c44a46693e",
      "cb016a4737ef420dbb19388736d9f460",
      "cc99f76b32084c29a401cf2fe1c16a44",
      "389c501b5ce34ce4a6552f9463a016d8",
      "9be34ca6e61c44c7841a1ee8acc3d66d",
      "18ad743e3a814abc944f416e233ff387",
      "85dd1752ff5a4804825e5d2b35c2a6ef",
      "f598da449704422daba21c7bbe474862",
      "4379aeb4dc41494fa8dcc10ca16fe844",
      "2d9984c634de48228c680f7ce16ea79c",
      "41eacbe3016944ee9758786da24224f9"
     ]
    },
    "id": "wpOfL0AiXO7-",
    "outputId": "f0a8256b-c29d-47e7-99dd-39b3fe9c79ea"
   },
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "llm_raw = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.0,\n",
    "    context_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vP2f4hXXTQO"
   },
   "outputs": [],
   "source": [
    "from langchain_core.language_models import LLM\n",
    "from typing import Any, List\n",
    "\n",
    "class CTransformersLLM(LLM):\n",
    "    model: Any\n",
    "\n",
    "    def _call(self, prompt: str, stop: List[str] = None) -> str:\n",
    "        output = self.model(prompt)\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                output = output.split(s)[0]\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self):\n",
    "        return {\"model\": \"ctransformers\"}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ctransformers\"\n",
    "\n",
    "llm = CTransformersLLM(model=llm_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTmVxUJWXfps"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "QA_PROMPT = \"\"\"You are an assistant for question answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "If no context is present or you don't know the answer, just say \"I don't know\".\n",
    "Do not make up the answer.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(QA_PROMPT)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"context\") | RunnableLambda(format_docs),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFNUZIsgXiyk",
    "outputId": "39617ec4-60a6-42ee-febd-022a01216f5d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "query = \"What is the capital of India?\"\n",
    "retrieved_docs = [\n",
    "    Document(page_content=\"New Delhi is the capital of India.\"),\n",
    "    Document(page_content=\"India is a country in South Asia.\"),\n",
    "]\n",
    "\n",
    "result = qa_rag_chain.invoke({\n",
    "    \"question\": query,\n",
    "    \"context\": retrieved_docs\n",
    "})\n",
    "\n",
    "print(\"Answer:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZVGaqpMYWZt",
    "outputId": "acd303e4-a7c7-4083-df4f-18adf19d35f3"
   },
   "outputs": [],
   "source": [
    "query = \"What is the capital of India?\"\n",
    "\n",
    "top5_docs = similarity_threshold.invoke(query)\n",
    "\n",
    "result = qa_rag_chain.invoke({\n",
    "    'question': query,\n",
    "    'context': top5_docs\n",
    "})\n",
    "\n",
    "print(\"Answer:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_Y0OyKmIckN"
   },
   "source": [
    "create query rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ag6mNHMyc3Sc"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "SYS_PROMPT = \"\"\"You are a question rewriter. Your task is to:\n",
    "1. Convert the following input question into a better version optimized for web search.\n",
    "2. When rewriting, understand the semantic intent of the original question.\n",
    "3. Return only the rewritten question and nothing else.\n",
    "If the question is already optimal, return it unchanged.\"\"\"\n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"Here is the initial question: {question}. Rewrite it.\")\n",
    "])\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZYInuvnc6Se",
    "outputId": "85139839-e1b8-4b37-f6f1-cf0ebb262786"
   },
   "outputs": [],
   "source": [
    "query = \"Who won champions league in 2024?\"\n",
    "\n",
    "rewritten = question_rewriter.invoke({\"question\": query})\n",
    "print(\"Rewritten Question:\", rewritten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIdvPieIKWmD"
   },
   "source": [
    "load web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bS6N3ThyemEB",
    "outputId": "882d9913-2566-411a-e5c2-20ff9494915b"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\" )\n",
    "\n",
    "results = tavily_tool.invoke(\"What is the capital of India?\")\n",
    "#print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOXK0ILzK5Vy"
   },
   "source": [
    "build agentic rag component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7znnLf2LFPm"
   },
   "source": [
    "graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCInpLxL3b-X"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZFku5OoLk4s"
   },
   "source": [
    "retrieve function for reterival from vector db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTUPFrHbIPjJ"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_text(text):\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def retrieve(state):\n",
    "    print(\"\\n Entered: retrieve\")\n",
    "    question = state[\"question\"]\n",
    "    print(\"Question:\", question)\n",
    "    print(\" Total docs in vectorstore:\", len(vectorstore.get()))\n",
    "\n",
    "    documents = similarity_threshold.invoke(question)\n",
    "    print(f\" Retrieved {len(documents)} documents\")\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        content_hash = hash_text(doc.page_content)\n",
    "        print(f\"\\n Doc #{i+1} (hash: {content_hash})\")\n",
    "        print(doc.page_content[:300].strip())\n",
    "        print(\" Metadata:\", doc.metadata)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwYpv8qsMZU_"
   },
   "source": [
    "grade docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPQMIJauMa8J"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_text(text):\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"\\nEntered: grade_documents\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "\n",
    "    if not documents:\n",
    "        print(\"No documents retrieved\")\n",
    "        return {\"documents\": [], \"question\": question, \"web_search_needed\": \"Yes\"}\n",
    "\n",
    "    print(f\"Total documents received: {len(documents)}\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        content_hash = hash_text(doc.page_content)\n",
    "        print(f\"\\n Document #{i+1} (hash: {content_hash})\")\n",
    "        print(doc.page_content[:300].strip())\n",
    "        print(\"Metadata:\", doc.metadata)\n",
    "\n",
    "        prompt_input = {\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content\n",
    "        }\n",
    "        print(\" Prompt Input to Grader:\\n\", prompt_input)\n",
    "\n",
    "        grade = safe_invoke_with_json_extraction(doc_grader, prompt_input)\n",
    "        print(\"Grader Output:\", grade)\n",
    "\n",
    "        if grade.get(\"binary_score\") == \"yes\":\n",
    "            print(\"Marked relevant\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\" Marked irrelevant\")\n",
    "\n",
    "    web_search_needed = \"Yes\" if len(filtered_docs) == 0 else \"No\"\n",
    "\n",
    "    print(f\"\\n Final relevant docs: {len(filtered_docs)} / {len(documents)}\")\n",
    "    print(f\" Web search needed? {web_search_needed}\")\n",
    "\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"web_search_needed\": web_search_needed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qeKnq9YNs8w"
   },
   "source": [
    "rewrite query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aAo7nSpMbFb"
   },
   "outputs": [],
   "source": [
    "def rewrite_query(state):\n",
    "  print(\"rewrite query\")\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "  #rewrite\n",
    "  better_questions = question_rewriter.invoke({\"question\": question})\n",
    "  return {\"documents\": documents, \"question\": better_questions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUs_SuLaN6dp"
   },
   "source": [
    "web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qR8MsHNQS0M"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def web_search(state):\n",
    "    print(\"Entered: web_search\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # web search\n",
    "    docs = tavily_tool.invoke(question)\n",
    "\n",
    "    if isinstance(docs, str):\n",
    "        try:\n",
    "            import json\n",
    "            docs = json.loads(docs)\n",
    "        except Exception as e:\n",
    "            #print(\"Failed to parse Tavily output\")\n",
    "            return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "    if not isinstance(docs, list):\n",
    "        #print(\"Unexpected Tavily response type:\", type(docs))\n",
    "        return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "    web_docs = [\n",
    "        Document(page_content=d[\"content\"], metadata={\"source\": d.get(\"url\")})\n",
    "        for d in docs if isinstance(d, dict) and \"content\" in d\n",
    "    ]\n",
    "\n",
    "    if web_docs:\n",
    "        #print(f\"Added {len(web_docs)} Tavily web docs\")\n",
    "        documents += web_docs\n",
    "    else:\n",
    "        #print(\" No usable content from Tavily\")\n",
    "\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbXCl19eOfl2"
   },
   "source": [
    "generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmFOXhI9Ogxd"
   },
   "outputs": [],
   "source": [
    "def generate_answer(state):\n",
    "  print(\"generate answer\")\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "  #generate answer\n",
    "  generation = qa_rag_chain.invoke({\"question\": question, \"context\": documents})\n",
    "  return {\"documents\":documents,\"generation\": generation, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ote4--FHO79N"
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "  print(\"decide to generate\")\n",
    "  web_search_needed = state[\"web_search_needed\"]\n",
    "  if web_search_needed == \"Yes\":\n",
    "    print(\"relevant docs not available\")\n",
    "    return \"rewrite_query\"\n",
    "  else:\n",
    "    print(\"relevant docs avilable\")\n",
    "    return \"generate_answer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6k2bU_jPcxD"
   },
   "source": [
    "build agent graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky5uAe5E31tF"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "\n",
    "agentic_rag.add_node(\"retrieve\", retrieve)\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents)\n",
    "agentic_rag.add_node(\"rewrite_query\", rewrite_query)\n",
    "agentic_rag.add_node(\"web_search\", web_search)\n",
    "agentic_rag.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "agentic_rag.set_entry_point(\"retrieve\")\n",
    "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        \"generate_answer\": \"generate_answer\"\n",
    "    }\n",
    ")\n",
    "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
    "agentic_rag.add_edge(\"generate_answer\", END)\n",
    "\n",
    "agentic_rag = agentic_rag.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "audySC3M4LNs",
    "outputId": "20d8b1e0-2fd5-4700-be93-b3be2237255a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJGE7nYFcu2i"
   },
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIGCCgYHPvdp",
    "outputId": "c491acbb-527a-47ae-d931-cfb82e64315f"
   },
   "outputs": [],
   "source": [
    "query = \"what is the capital of India?\"\n",
    "\n",
    "RESPONSE = agentic_rag.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "SXbN4kmyc6mc",
    "outputId": "655e32b4-8fd9-4a92-c4ae-f587a06597b3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(RESPONSE[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIQP7-6nG8cJ",
    "outputId": "0c2f1dfb-53d0-4f09-96fb-bdb84b42d53a"
   },
   "outputs": [],
   "source": [
    "query = \"Who won the champions league in 2024?\"\n",
    "\n",
    "RESPONSE = agentic_rag.invoke({\"question\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dthoVQLN4lH",
    "outputId": "29127596-6095-4c3b-b81c-cb178cf614fc"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(RESPONSE[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTp4dFj_c6j4",
    "outputId": "d8593fb5-6865-4626-be11-bce66f8400ca"
   },
   "outputs": [],
   "source": [
    "query = \"Tell me about India\"\n",
    "\n",
    "RESPONSE = agentic_rag.invoke({\"question\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "_FiUeDk8oX2S",
    "outputId": "d37afa2b-4a56-4382-83db-c74d7821b761"
   },
   "outputs": [],
   "source": [
    "display(Markdown(RESPONSE[\"generation\"]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
